{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e358eb60-fc6d-46aa-ade7-20ab194020e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Attention, Concatenate, Lambda, Masking\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b057a729-d83d-423a-9ade-46727fdbfcb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Things to do\n",
    "- Evaluate the efficacy of the AE (adjust the hyperparameters)\n",
    "- Figure out how to get directionlity of connections\n",
    "\t- Could take the correlatin of the 2nd AE node time series with the phenotype\n",
    "- Check the predictability of the model for benchmarking\n",
    "- Evaluate the amount of loss for both of the autoencoders\n",
    "\"\"\"\n",
    "\n",
    "folder_path = '/home/nbrady/Desktop/deep_functional_net'\n",
    "phenotypes = pd.read_csv(f'{folder_path}/PHEN_MATRIX.csv')\n",
    "\n",
    "# Exclude these Subs for FD issues\n",
    "ignore_subs = [5027, 5011, 5140, 5142, 5172, 5036, 5106]\n",
    "included_subs = phenotypes['sid_rise']\n",
    "\n",
    "# Phenotype of interest\n",
    "phen_var = 'STATE_Tot_all_pn1'\n",
    "phen_data = np.array([])\n",
    "\n",
    "# Define a similarity metric (e.g., cosine similarity)\n",
    "def cosine_similarity(a, b):\n",
    "        dot_product = np.dot(a, b)\n",
    "        norm_a = np.linalg.norm(a)\n",
    "        norm_b = np.linalg.norm(b)\n",
    "        return dot_product / (norm_a * norm_b)\n",
    "\n",
    "def softmax(matrix, axis=1):\n",
    "        mean_value = np.mean(matrix)\n",
    "        # Create a mask to exclude the values over mean\n",
    "        binary_mask = (matrix > mean_value).astype(int)\n",
    "\n",
    "        # Actual softmax function\n",
    "        exponentiated_values = np.exp(-(matrix - mean_value))\n",
    "        sum_exponentiated_values = np.sum(exponentiated_values, axis=axis, keepdims=True)\n",
    "        softmax_result = exponentiated_values / sum_exponentiated_values\n",
    "\n",
    "        # Mask values over mean\n",
    "        masked_result = softmax_result + binary_mask\n",
    "        return masked_result\n",
    "\n",
    "def dynamic_time_warp(x, y):\n",
    "        # Create the distance matrix.\n",
    "        D = np.zeros((len(x), len(y)))\n",
    "\n",
    "        for i in range(len(x)):\n",
    "                for j in range(len(y)):\n",
    "                        D[i, j] = np.abs(x[i] - y[j])\n",
    "\n",
    "        # Compute the cumulative distance matrix.\n",
    "        for i in range(1, len(x)):\n",
    "                for j in range(1, len(y)):\n",
    "                        D[i, j] += np.min([D[i - 1, j], D[i, j - 1], D[i - 1, j - 1]])\n",
    "\n",
    "        # Return the distance at the last row and column of the matrix.\n",
    "        return D[-1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "540dff4f-e277-40b0-a43e-e9082135503b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2736, 268) 0 sub-5000mom_realcry_denoised_bold_timeseries.csv\n",
      "(3170, 268) 1 sub-5001mom_realcry_denoised_bold_timeseries.csv\n",
      "(3606, 268) 2 sub-5002mom_realcry_denoised_bold_timeseries.csv\n",
      "(4040, 268) 3 sub-5003mom_realcry_denoised_bold_timeseries.csv\n",
      "(4473, 268) 4 sub-5005mom_realcry_denoised_bold_timeseries.csv\n",
      "(4908, 268) 5 sub-5007mom_realcry_denoised_bold_timeseries.csv\n",
      "(5344, 268) 6 sub-5008mom_realcry_denoised_bold_timeseries.csv\n",
      "(5778, 268) 7 sub-5010mom_realcry_denoised_bold_timeseries.csv\n",
      "(6432, 268) 9 sub-5013mom_realcry_denoised_bold_timeseries.csv\n",
      "(6869, 268) 10 sub-5015mom_realcry_denoised_bold_timeseries.csv\n",
      "(7304, 268) 11 sub-5016mom_realcry_denoised_bold_timeseries.csv\n",
      "(7738, 268) 12 sub-5017mom_realcry_denoised_bold_timeseries.csv\n",
      "(8159, 268) 13 sub-5018mom_realcry_denoised_bold_timeseries.csv\n",
      "(8594, 268) 14 sub-5019mom_realcry_denoised_bold_timeseries.csv\n",
      "(8937, 268) 15 sub-5020mom_realcry_denoised_bold_timeseries.csv\n",
      "(9329, 268) 16 sub-5021mom_realcry_denoised_bold_timeseries.csv\n",
      "(9719, 268) 17 sub-5022mom_realcry_denoised_bold_timeseries.csv\n",
      "(10147, 268) 18 sub-5023mom_realcry_denoised_bold_timeseries.csv\n",
      "(10540, 268) 19 sub-5024mom_realcry_denoised_bold_timeseries.csv\n",
      "(10975, 268) 20 sub-5026mom_realcry_denoised_bold_timeseries.csv\n",
      "(11581, 268) 22 sub-5029mom_realcry_denoised_bold_timeseries.csv\n",
      "(11800, 268) 23 sub-5030mom_realcry_denoised_bold_timeseries.csv\n",
      "(12182, 268) 24 sub-5033mom_realcry_denoised_bold_timeseries.csv\n",
      "(12487, 268) 25 sub-5034mom_realcry_denoised_bold_timeseries.csv\n",
      "(12920, 268) 26 sub-5035mom_realcry_denoised_bold_timeseries.csv\n",
      "(13704, 268) 28 sub-5039mom_realcry_denoised_bold_timeseries.csv\n",
      "(14137, 268) 29 sub-5040mom_realcry_denoised_bold_timeseries.csv\n",
      "(14527, 268) 30 sub-5041mom_realcry_denoised_bold_timeseries.csv\n",
      "(14964, 268) 31 sub-5042mom_realcry_denoised_bold_timeseries.csv\n",
      "(15400, 268) 32 sub-5043mom_realcry_denoised_bold_timeseries.csv\n",
      "(15791, 268) 33 sub-5044mom_realcry_denoised_bold_timeseries.csv\n",
      "(16223, 268) 34 sub-5045mom_realcry_denoised_bold_timeseries.csv\n",
      "(16657, 268) 35 sub-5047mom_realcry_denoised_bold_timeseries.csv\n",
      "(17046, 268) 36 sub-5048mom_realcry_denoised_bold_timeseries.csv\n",
      "(17481, 268) 37 sub-5049mom_realcry_denoised_bold_timeseries.csv\n",
      "(17918, 268) 38 sub-5052mom_realcry_denoised_bold_timeseries.csv\n",
      "(18353, 268) 39 sub-5053mom_realcry_denoised_bold_timeseries.csv\n",
      "(18790, 268) 40 sub-5054mom_realcry_denoised_bold_timeseries.csv\n",
      "(19226, 268) 41 sub-5058mom_realcry_denoised_bold_timeseries.csv\n",
      "(19661, 268) 42 sub-5060mom_realcry_denoised_bold_timeseries.csv\n",
      "(20099, 268) 43 sub-5061mom_realcry_denoised_bold_timeseries.csv\n",
      "(20490, 268) 44 sub-5062mom_realcry_denoised_bold_timeseries.csv\n",
      "(20927, 268) 45 sub-5064mom_realcry_denoised_bold_timeseries.csv\n",
      "(21361, 268) 46 sub-5067mom_realcry_denoised_bold_timeseries.csv\n",
      "(21794, 268) 47 sub-5069mom_realcry_denoised_bold_timeseries.csv\n",
      "(22228, 268) 48 sub-5071mom_realcry_denoised_bold_timeseries.csv\n",
      "(22666, 268) 49 sub-5072mom_realcry_denoised_bold_timeseries.csv\n",
      "(23058, 268) 50 sub-5074mom_realcry_denoised_bold_timeseries.csv\n",
      "(23494, 268) 51 sub-5076mom_realcry_denoised_bold_timeseries.csv\n",
      "(23916, 268) 52 sub-5077mom_realcry_denoised_bold_timeseries.csv\n",
      "(24332, 268) 53 sub-5084mom_realcry_denoised_bold_timeseries.csv\n",
      "(24765, 268) 54 sub-5087mom_realcry_denoised_bold_timeseries.csv\n",
      "(25199, 268) 55 sub-5089mom_realcry_denoised_bold_timeseries.csv\n",
      "(25601, 268) 56 sub-5090mom_realcry_denoised_bold_timeseries.csv\n",
      "(34154, 268) 57 sub-5092mom_realcry_denoised_bold_timeseries.csv\n",
      "(26464, 268) 58 sub-5093mom_realcry_denoised_bold_timeseries.csv\n",
      "(26813, 268) 59 sub-5096mom_realcry_denoised_bold_timeseries.csv\n",
      "(27248, 268) 60 sub-5098mom_realcry_denoised_bold_timeseries.csv\n",
      "(434, 268) 61 sub-5101mom_realcry_denoised_bold_timeseries.csv\n",
      "(871, 268) 62 sub-5102mom_realcry_denoised_bold_timeseries.csv\n",
      "(1283, 268) 63 sub-5103mom_realcry_denoised_bold_timeseries.csv\n",
      "(1546, 268) 64 sub-5105mom_realcry_denoised_bold_timeseries.csv\n",
      "(2300, 268) 66 sub-5108mom_realcry_denoised_bold_timeseries.csv\n",
      "(34590, 268) 67 sub-5125mom_realcry_denoised_bold_timeseries.csv\n",
      "(28509, 268) 68 sub-5128mom_realcry_denoised_bold_timeseries.csv\n",
      "(28944, 268) 69 sub-5137mom_realcry_denoised_bold_timeseries.csv\n",
      "(29988, 268) 72 sub-5145mom_realcry_denoised_bold_timeseries.csv\n",
      "(28074, 268) 73 sub-5146mom_realcry_denoised_bold_timeseries.csv\n",
      "(30378, 268) 74 sub-5149mom_realcry_denoised_bold_timeseries.csv\n",
      "(27639, 268) 75 sub-5150mom_realcry_denoised_bold_timeseries.csv\n",
      "(30815, 268) 76 sub-5154mom_realcry_denoised_bold_timeseries.csv\n",
      "(26030, 268) 77 sub-5156mom_realcry_denoised_bold_timeseries.csv\n",
      "(31248, 268) 78 sub-5159mom_realcry_denoised_bold_timeseries.csv\n",
      "(31681, 268) 79 sub-5164mom_realcry_denoised_bold_timeseries.csv\n",
      "(32117, 268) 80 sub-5168mom_realcry_denoised_bold_timeseries.csv\n",
      "(35022, 268) 81 sub-5170mom_realcry_denoised_bold_timeseries.csv\n",
      "(32943, 268) 83 sub-5173mom_realcry_denoised_bold_timeseries.csv\n",
      "(33378, 268) 84 sub-5177mom_realcry_denoised_bold_timeseries.csv\n",
      "(35805, 268) 85 sub-5178mom_realcry_denoised_bold_timeseries.csv\n",
      "(33804, 268) 86 sub-5179mom_realcry_denoised_bold_timeseries.csv\n",
      "(36209, 268) 87 sub-5182mom_realcry_denoised_bold_timeseries.csv\n",
      "(32507, 268) 88 sub-5185mom_realcry_denoised_bold_timeseries.csv\n",
      "(82, 36209, 268)\n"
     ]
    }
   ],
   "source": [
    "#=======================================================\n",
    "# Load in the bold timeseries to create Nx268x268 matrix\n",
    "#=======================================================\n",
    "num_subs = len(os.listdir(f\"{folder_path}/timeseries\"))\n",
    "timeseries_compression = 100\n",
    "\n",
    "#all_data = np.zeros((num_subs, 2736, 268))\n",
    "all_data = []\n",
    "\n",
    "ts_data = os.listdir(f\"{folder_path}/timeseries\")\n",
    "\n",
    "for sub_id, sub in enumerate(ts_data):\n",
    "    # Ignore subjects with missing data or with high FD values\n",
    "    rise_id = int(sub.split('_')[0].split('-')[-1].split('m')[0])\n",
    "    sub_df = phenotypes[phenotypes['sid_rise'] == rise_id]\n",
    "    sub_phen_val = sub_df[phen_var].values[0] if len(sub_df[phen_var].values) > 0 else None\n",
    "    use_data = (rise_id not in ignore_subs) or (sub_phen_val != None)\n",
    "    \n",
    "    if use_data == True:\n",
    "        path = f\"{folder_path}/timeseries/{sub}\"\n",
    "        # Read in the CSV\n",
    "        data = pd.read_csv(path)\n",
    "        #print(data.shape, sub)\n",
    "        data = data.T\n",
    "        data = data.drop('Unnamed: 0')\n",
    "        data = data.T\n",
    "        all_data.append(data)\n",
    "        print(data.shape, sub_id, sub)\n",
    "\n",
    "# Pad sequences\n",
    "padded_data = pad_sequences(all_data, padding='post')        \n",
    "print(padded_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37a16d4d-dc34-40e8-8c9a-cd22e0019309",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 36209 268\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 21\u001b[0m\n\u001b[1;32m     11\u001b[0m encoder \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m     12\u001b[0m     layers\u001b[38;5;241m.\u001b[39mInputLayer(input_shape\u001b[38;5;241m=\u001b[39minput_shape),\n\u001b[1;32m     13\u001b[0m     layers\u001b[38;5;241m.\u001b[39mMasking(mask_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m),  \u001b[38;5;66;03m# Masking layer to ignore zeros\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     layers\u001b[38;5;241m.\u001b[39mLSTM(latent_dim, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),  \u001b[38;5;66;03m# Bottleneck layer\u001b[39;00m\n\u001b[1;32m     17\u001b[0m ])\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Decoder with additional hidden layers, mirroring the encoder's structure\u001b[39;00m\n\u001b[1;32m     20\u001b[0m decoder \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m---> 21\u001b[0m     layers\u001b[38;5;241m.\u001b[39mRepeatVector(all_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]),  \u001b[38;5;66;03m# all_data.shape[1] should be the number of timesteps\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     layers\u001b[38;5;241m.\u001b[39mLSTM(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),  \u001b[38;5;66;03m# Symmetrical expansion\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     layers\u001b[38;5;241m.\u001b[39mLSTM(\u001b[38;5;241m512\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),  \u001b[38;5;66;03m# More neurons\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     layers\u001b[38;5;241m.\u001b[39mLSTM(all_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Output layer to match input features\u001b[39;00m\n\u001b[1;32m     25\u001b[0m ])\n\u001b[1;32m     27\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSequential([encoder, decoder])\n\u001b[1;32m     29\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSprop\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "#=================================================================\n",
    "# Train the autoencoder for y dimension reduction for each subject\n",
    "#=================================================================\n",
    "\n",
    "# Autoencoder architecture\n",
    "input_shape = (padded_data.shape[1], padded_data.shape[2])\n",
    "print(padded_data.shape[0], padded_data.shape[1], padded_data.shape[2])\n",
    "latent_dim = 100  # Adjust based on your requirements\n",
    "\n",
    "# Encoder with additional hidden layers\n",
    "encoder = models.Sequential([\n",
    "    layers.InputLayer(input_shape=input_shape),\n",
    "    layers.Masking(mask_value=0.),  # Masking layer to ignore zeros\n",
    "    layers.LSTM(512, activation='tanh', return_sequences=True),  # More neurons and return sequences\n",
    "    layers.LSTM(256, activation='tanh', return_sequences=True),  # Gradual compression\n",
    "    layers.LSTM(latent_dim, activation='tanh', return_sequences=False),  # Bottleneck layer\n",
    "])\n",
    "\n",
    "# Decoder with additional hidden layers, mirroring the encoder's structure\n",
    "decoder = models.Sequential([\n",
    "    layers.RepeatVector(padded_data.shape[1]),  # all_data.shape[1] should be the number of timesteps\n",
    "    layers.LSTM(256, activation='tanh', return_sequences=True),  # Symmetrical expansion\n",
    "    layers.LSTM(512, activation='tanh', return_sequences=True),  # More neurons\n",
    "    layers.LSTM(padded_data.shape[2], activation='sigmoid', return_sequences=True)  # Output layer to match input features\n",
    "])\n",
    "\n",
    "autoencoder = models.Sequential([encoder, decoder])\n",
    "\n",
    "autoencoder.compile(optimizer='RMSprop', loss='mse')\n",
    "\n",
    "# Train the autoencoder\n",
    "history = autoencoder.fit(padded_data, padded_data, epochs=50, validation_split=0.2, batch_size=16, shuffle=True,)\n",
    "\n",
    "# Generate synthetic data (example using random noise as input)\n",
    "noise = np.random.normal(size=(50, latent_dim))\n",
    "synthetic_data = decoder.predict(noise)\n",
    "\n",
    "# Plotting\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "plt.savefig('autoencoder_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52b6feed-2072-4d76-9247-2fbfdff6ee86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2736, 268)\n",
      "3/3 [==============================] - 19s 6s/step\n",
      "Mean Squared Error: 20.004639552785633\n"
     ]
    }
   ],
   "source": [
    "print(synthetic_data.shape)\n",
    "\n",
    "# Evaluate efficacy\n",
    "reconstructed_data = autoencoder.predict(all_data)\n",
    "mse = np.mean(np.square(all_data - reconstructed_data))\n",
    "#cossim = cosine_similarity(all_data, reconstructed_data)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130fca08-215e-4328-9d7d-4d31de0861a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model as a `.keras` zip archive.\n",
    "decoder.save('cpm_synthetic_data_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
